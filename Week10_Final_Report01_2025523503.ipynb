{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP9xePQL7xLU",
        "outputId": "daf0b42f-cc2b-4a23-9d7b-8dfd4f80223e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: finterstellar in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.2)\n",
            "Requirement already satisfied: lxml>=4.2.6 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from finterstellar) (6.0.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from finterstellar) (2.3.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from finterstellar) (2.3.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from finterstellar) (2.32.4)\n",
            "Requirement already satisfied: matplotlib>=3.8.3 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from finterstellar) (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.8.3->finterstellar) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.8.3->finterstellar) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.8.3->finterstellar) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.8.3->finterstellar) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\shin\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib>=3.8.3->finterstellar) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.8.3->finterstellar) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib>=3.8.3->finterstellar) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shin\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib>=3.8.3->finterstellar) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.1.4->finterstellar) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas>=1.1.4->finterstellar) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\shin\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib>=3.8.3->finterstellar) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->finterstellar) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->finterstellar) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->finterstellar) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.23.0->finterstellar) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install finterstellar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Dlf5nY6D71r1"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "import finterstellar as fs\n",
        "#System trading Library 설치: Finterstellar\n",
        "\n",
        "import io, sys, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KV8gwmMmFZ9B"
      },
      "outputs": [],
      "source": [
        "symbol_ = 'TSLA'\n",
        "start_date_ = '2020-06-30'\n",
        "end_date_ = '2025-06-30'\n",
        "fee_ = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27QZPb_P2nzR",
        "outputId": "59828b43-38a7-4166-abfc-3510d5e44632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rsi 디렉토리가 생성되었거나 이미 존재합니다.\n",
            "macd 디렉토리가 생성되었거나 이미 존재합니다.\n",
            "stochastic 디렉토리가 생성되었거나 이미 존재합니다.\n"
          ]
        }
      ],
      "source": [
        "path_list = [\"rsi\",\"macd\",\"stochastic\"]\n",
        "\n",
        "for path in path_list :\n",
        "    try:\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        print(f\"{path} 디렉토리가 생성되었거나 이미 존재합니다.\")\n",
        "    except OSError as e:\n",
        "        print(f\"디렉토리 생성 중 오류 발생: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-gVgsROwf2e8"
      },
      "outputs": [],
      "source": [
        "# Performance 문자열을 Parsing 하여 반환하는 함수\n",
        "def parse_performance_output(output_text):\n",
        "    result = {}\n",
        "    for line in output_text.strip().split(\"\\n\"):\n",
        "        # 콜론으로 분리\n",
        "        if \":\" not in line:\n",
        "            continue\n",
        "        key, value = line.split(\":\", 1)\n",
        "        key = key.strip()\n",
        "        value = value.strip()\n",
        "\n",
        "        # 퍼센트 처리\n",
        "        if value.endswith(\"%\"):\n",
        "            num = float(value.strip(\"%\")) / 100\n",
        "            result[key] = num\n",
        "        # 연도 처리\n",
        "        elif value.endswith(\"yrs\"):\n",
        "            num = float(value.strip(\"yrs\"))\n",
        "            result[key] = num\n",
        "        # 숫자 처리\n",
        "        else:\n",
        "            try:\n",
        "                result[key] = float(value)\n",
        "            except ValueError:\n",
        "                result[key] = value  # 혹시 문자열이면 그대로 저장\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_Ge4h1QzJGJv"
      },
      "outputs": [],
      "source": [
        "# 1. RSI Performance and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TdL9y1AfLpVG"
      },
      "outputs": [],
      "source": [
        "# RSI 를 구해서 dict 를 반환하는 함수\n",
        "def get_rsi_performance_dict(symbol_, df, params) :\n",
        "    w_, buy_, sell_, fee_ = params\n",
        "\n",
        "    # dataFrame 초기화\n",
        "    df_tmp = df.copy()\n",
        "\n",
        "    result_dict = {}\n",
        "\n",
        "    # 파라미터 추가\n",
        "    result_dict[\"symbol\"] = symbol_\n",
        "    result_dict[\"w_param\"] = w_\n",
        "    result_dict[\"buy_param\"] = buy_\n",
        "    result_dict[\"sell_param\"] = sell_\n",
        "    result_dict[\"fee_\"] = fee_\n",
        "\n",
        "    perf = {}\n",
        "\n",
        "    # RSI 계산, indicator signal 도출, position 계산, 평가 및 performance 측정\n",
        "    fs.rsi(df_tmp, w=w_)\n",
        "    fs.indicator_to_signal(df_tmp, factor='rsi', buy=buy_, sell=sell_)\n",
        "    fs.position(df_tmp)\n",
        "    fs.evaluate(df_tmp, cost= fee_)\n",
        "\n",
        "    # print 값 변수화\n",
        "    capture = io.StringIO()\n",
        "    # stdout 백업\n",
        "    old_stdout = sys.stdout\n",
        "\n",
        "    try:\n",
        "        # stdout을 StringIO로 바꿈\n",
        "        sys.stdout = capture\n",
        "\n",
        "        # Performance 함수 실행 (print만 함)\n",
        "        fs.performance(df_tmp, rf_rate=0.02)\n",
        "\n",
        "    finally:\n",
        "        # stdout 복원\n",
        "        sys.stdout = old_stdout\n",
        "\n",
        "    # 캡처된 텍스트\n",
        "    output_text = capture.getvalue()\n",
        "    # performance dict 화\n",
        "    # performance_dict = parse_performance_output(output_text)\n",
        "    perf = parse_performance_output(output_text)\n",
        "\n",
        "    result_dict.update(perf)\n",
        "\n",
        "    print(f\"Performance Processing : {result_dict}\")\n",
        "\n",
        "    return result_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fgwas-iFXvoQ"
      },
      "outputs": [],
      "source": [
        "# MACD 를 구해서 dict 를 반환하는 함수\n",
        "def get_macd_performance_dict(symbol_, df, params) :\n",
        "    buy_, sell_, fee_ = params\n",
        "\n",
        "    # dataFrame 초기화\n",
        "    df_tmp = df.copy()\n",
        "\n",
        "    result_dict = {}\n",
        "\n",
        "    # 파라미터 추가\n",
        "    result_dict[\"symbol\"] = symbol_\n",
        "    result_dict[\"buy_param\"] = buy_\n",
        "    result_dict[\"sell_param\"] = sell_\n",
        "    result_dict[\"fee_\"] = fee_\n",
        "\n",
        "    perf = {}\n",
        "\n",
        "    # MACD 계산, indicator signal 도출, position 계산, 평가 및 performance 측정\n",
        "    fs.macd(df_tmp)\n",
        "    fs.indicator_to_signal(df_tmp, factor='macd', buy=buy_, sell=sell_)\n",
        "    fs.position(df_tmp)\n",
        "    fs.evaluate(df_tmp, cost= fee_)\n",
        "\n",
        "    # print 값 변수화\n",
        "    capture = io.StringIO()\n",
        "    # stdout 백업\n",
        "    old_stdout = sys.stdout\n",
        "\n",
        "    try:\n",
        "        # stdout을 StringIO로 바꿈\n",
        "        sys.stdout = capture\n",
        "\n",
        "        # Performance 함수 실행 (print만 함)\n",
        "        fs.performance(df_tmp, rf_rate=0.02)\n",
        "\n",
        "    finally:\n",
        "        # stdout 복원\n",
        "        sys.stdout = old_stdout\n",
        "\n",
        "    # 캡처된 텍스트\n",
        "    output_text = capture.getvalue()\n",
        "    # performance dict 화\n",
        "    # performance_dict = parse_performance_output(output_text)\n",
        "    perf = parse_performance_output(output_text)\n",
        "\n",
        "    result_dict.update(perf)\n",
        "\n",
        "    print(f\"Performance Processing : {result_dict}\")\n",
        "\n",
        "    return result_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fl_SjLPtXzvC"
      },
      "outputs": [],
      "source": [
        "# Stochastic 를 구해서 dict 를 반환하는 함수\n",
        "def get_stochastic_performance_dict(symbol_, df, params) :\n",
        "    factor_, buy_, sell_, fee_ = params\n",
        "\n",
        "    # dataFrame 초기화\n",
        "    df_tmp = df.copy()\n",
        "\n",
        "    result_dict = {}\n",
        "\n",
        "    # 파라미터 추가\n",
        "    result_dict[\"symbol\"] = symbol_\n",
        "    result_dict[\"factor\"] = factor_\n",
        "    result_dict[\"buy_param\"] = buy_\n",
        "    result_dict[\"sell_param\"] = sell_\n",
        "    result_dict[\"fee_\"] = fee_\n",
        "\n",
        "    perf = {}\n",
        "\n",
        "    # Stochastic 계산, indicator signal 도출, position 계산, 평가 및 performance 측정\n",
        "    fs.stochastic(df_tmp, symbol_, n=14, m=3, t=3)\n",
        "    # indicator 값 추출을 위한 전처리 작업\n",
        "    df_tmp['indicator'] = df_tmp['slow_k'] - df_tmp['slow_d']\n",
        "\n",
        "    fs.indicator_to_signal(df_tmp, factor= factor_, buy=buy_, sell=sell_)\n",
        "    fs.position(df_tmp)\n",
        "    fs.evaluate(df_tmp, cost= fee_)\n",
        "\n",
        "    # print 값 변수화\n",
        "    capture = io.StringIO()\n",
        "    # stdout 백업\n",
        "    old_stdout = sys.stdout\n",
        "\n",
        "    try:\n",
        "        # stdout을 StringIO로 바꿈\n",
        "        sys.stdout = capture\n",
        "\n",
        "        # Performance 함수 실행 (print만 함)\n",
        "        fs.performance(df_tmp, rf_rate=0.02)\n",
        "\n",
        "    finally:\n",
        "        # stdout 복원\n",
        "        sys.stdout = old_stdout\n",
        "\n",
        "    # 캡처된 텍스트\n",
        "    output_text = capture.getvalue()\n",
        "    # performance dict 화\n",
        "    # performance_dict = parse_performance_output(output_text)\n",
        "    perf = parse_performance_output(output_text)\n",
        "\n",
        "    result_dict.update(perf)\n",
        "\n",
        "    print(f\"Performance Processing : {result_dict}\")\n",
        "\n",
        "\n",
        "    return result_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "beoRL34Rh8Uw"
      },
      "outputs": [],
      "source": [
        "# 모든 팩터 집합을 이용해 최적의 RSI Parameter 계산\n",
        "# Parallel 을 이용해서 성능 개선\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_rsi_performance_dataframe(symbol, start_date_, end_date_, fee_) :\n",
        "\n",
        "    df = fs.get_price(symbol, start_date=start_date_, end_date=end_date_)\n",
        "    # df = pd.read_csv(f\"get_price_{symbol}_{start_date_}_to_{end_date_}.csv\", encoding=\"utf8\", index_col=0, parse_dates=True)\n",
        "\n",
        "    print(f\"[ {symbol} ] dataFrame.head \")\n",
        "    print(df.head(3))\n",
        "\n",
        "    # Parameter 집합 도출(list)\n",
        "    w_range = range(7,23+1)\n",
        "    buy_range = range(15,45+1)\n",
        "    sell_range = range(55,85+1)\n",
        "    param_list = [(w,buy,sell,fee_) for w in w_range for buy in buy_range for sell in sell_range]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # 최적의 w, buy_position, sell_position 을 찾기 위한 recursive\n",
        "    # For문 이용\n",
        "    # for w in range(7,23+1)\n",
        "    #   for buy in range(15, 45+1)\n",
        "    #       for sell in range(55,85+1)\n",
        "    #           results.append(get_rsi_performance_dict(df,w,buy,sell,fee_))\n",
        "\n",
        "    # Parallel 이용\n",
        "    results = Parallel(n_jobs=-1) (\n",
        "            delayed(get_rsi_performance_dict)(symbol, df, params) for params in tqdm(param_list)\n",
        "\n",
        "    )\n",
        "\n",
        "    df_result = pd.DataFrame(results)\n",
        "    return df_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WUt1GLbEaR4D"
      },
      "outputs": [],
      "source": [
        "# 모든 팩터 집합을 이용해 최적의 MACD Parameter 계산\n",
        "# Parallel 을 이용해서 성능 개선\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_macd_performance_dataframe(symbol, start_date_, end_date_, fee_) :\n",
        "\n",
        "    df = fs.get_price(symbol, start_date=start_date_, end_date=end_date_)\n",
        "    # df = pd.read_csv(f\"get_price_{symbol}_{start_date_}_to_{end_date_}.csv\", encoding=\"utf8\", index_col=0, parse_dates=True)\n",
        "\n",
        "    print(f\"[ {symbol} ] dataFrame.head \")\n",
        "    print(df.head(3))\n",
        "\n",
        "    # Parameter 집합 도출(list)\n",
        "    buy_range = range(-10,10+1)\n",
        "    sell_range = range(-10,10+1)\n",
        "    param_list = [(buy,sell,fee_) for buy in buy_range for sell in sell_range]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # 최적의 buy_position, sell_position 을 찾기 위한 recursive\n",
        "    # For문 이용\n",
        "    # for buy in range(-10,10+1)\n",
        "    #    for sell in range(-10,10+1)\n",
        "    #        results.append(get_macd_performance_dict(df,buy,sell,fee_))\n",
        "\n",
        "    # Parallel 이용\n",
        "    results = Parallel(n_jobs=-1) (\n",
        "            delayed(get_macd_performance_dict)(symbol, df, params) for params in tqdm(param_list)\n",
        "\n",
        "    )\n",
        "\n",
        "    df_result = pd.DataFrame(results)\n",
        "    return df_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Odp8-xqLaSmT"
      },
      "outputs": [],
      "source": [
        "# 모든 팩터 집합을 이용해 최적의 Stochastic Parameter 계산\n",
        "# Parallel 을 이용해서 성능 개선\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_stochastic_performance_dataframe(symbol, start_date_, end_date_, fee_) :\n",
        "\n",
        "    df = fs.get_ohlc(symbol, start_date=start_date_, end_date=end_date_)\n",
        "    # df = pd.read_csv(f\"get_ohlc_{symbol}_{start_date_}_to_{end_date_}.csv\", encoding=\"utf8\", index_col=0, parse_dates=True)\n",
        "\n",
        "    print(f\"[ {symbol} ] dataFrame.head \")\n",
        "    print(df.head(3))\n",
        "\n",
        "    # Parameter 집합 도출(list)\n",
        "    factor_list = ['slow_k','indicator']\n",
        "    buy_range = range(10,40+1)\n",
        "    sell_range = range(60,90+1)\n",
        "    param_list = [(factor_,buy,sell,fee_) for factor_ in factor_list for buy in buy_range for sell in sell_range]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # 최적의 buy_position, sell_position 을 찾기 위한 recursive\n",
        "    # For문 이용\n",
        "    # for factor in factor_list\n",
        "    #   for buy in range(10, 40+1)\n",
        "    #       for sell in range(60,90+1)\n",
        "    #           results.append(get_stochastics_performance_dict(factor,buy,sell,fee_))\n",
        "\n",
        "    # Parallel 이용\n",
        "    results = Parallel(n_jobs=-1) (\n",
        "            delayed(get_stochastic_performance_dict)(symbol, df, params) for params in tqdm(param_list)\n",
        "    )\n",
        "\n",
        "    df_result = pd.DataFrame(results)\n",
        "    return df_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "uXnSTn2rjlah"
      },
      "outputs": [],
      "source": [
        "symbol_list = ['^GSPC', '^KS11','MSFT', 'GOOG', 'AMZN', 'META', 'NVDA', 'TSLA', 'AAPL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH5x_lyyjM8u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ ^GSPC ] dataFrame.head \n",
            "               Open     High      Low    Close      Volume  Adj Close\n",
            "2020-06-30 3,050.20 3,111.51 3,047.83 3,100.29  4705850000   3,100.29\n",
            "2020-07-01 3,105.92 3,128.44 3,101.17 3,115.86  4449230000   3,115.86\n",
            "2020-07-02 3,143.64 3,165.81 3,124.52 3,130.01  4197720000   3,130.01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1922/1922 [00:12<00:00, 158.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ ^KS11 ] dataFrame.head \n",
            "               Open     High      Low    Close   Volume  Adj Close\n",
            "2020-06-30 2,124.38 2,134.38 2,108.26 2,108.33   708600   2,108.33\n",
            "2020-07-01 2,128.81 2,133.55 2,101.33 2,106.70  1116200   2,106.70\n",
            "2020-07-02 2,116.72 2,135.37 2,113.98 2,135.37  1092000   2,135.37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1922/1922 [00:06<00:00, 315.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ MSFT ] dataFrame.head \n",
            "             Open   High    Low  Close    Volume  Adj Close\n",
            "2020-06-30 197.88 204.40 197.74 203.51  34310300     194.98\n",
            "2020-07-01 203.14 206.35 201.77 204.70  32061200     196.12\n",
            "2020-07-02 205.68 208.02 205.00 206.26  29315800     197.61\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1922/1922 [00:07<00:00, 268.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ GOOG ] dataFrame.head \n",
            "            Open  High   Low  Close    Volume  Adj Close\n",
            "2020-06-30 69.52 70.93 69.20  70.68  40848000      70.26\n",
            "2020-07-01 70.56 72.15 70.49  71.90  35504000      71.48\n",
            "2020-07-02 72.35 74.15 72.32  73.24  37182000      72.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1922/1922 [00:07<00:00, 245.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ AMZN ] dataFrame.head \n",
            "             Open   High    Low  Close     Volume  Adj Close\n",
            "2020-06-30 134.25 138.48 133.75 137.94   75394000     137.94\n",
            "2020-07-01 137.90 144.75 137.70 143.93  127268000     143.93\n",
            "2020-07-02 145.60 147.78 143.55 144.51  131868000     144.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Parameter 조합을 csv 로 저장\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m symbol \u001b[38;5;129;01min\u001b[39;00m symbol_list :\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# df_rsi = get_rsi_performance_dataframe(symbol, start_date_, end_date_, fee_)\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# df_macd = get_macd_performance_dataframe(symbol, start_date_, end_date_, fee_)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     df_sto = \u001b[43mget_stochastic_performance_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfee_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# write csv\u001b[39;00m\n\u001b[32m      8\u001b[39m     df_rsi.to_csv(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m./rsi/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_date_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_to_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_date_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m,encoding=\u001b[33m'\u001b[39m\u001b[33mutf8\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mget_stochastic_performance_dataframe\u001b[39m\u001b[34m(symbol, start_date_, end_date_, fee_)\u001b[39m\n\u001b[32m     20\u001b[39m results = []\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# 최적의 buy_position, sell_position 을 찾기 위한 recursive\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# For문 이용\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# for factor in factor_list\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Parallel 이용\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_stochastic_performance_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m df_result = pd.DataFrame(results)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df_result\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SHIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Parameter 조합을 csv 로 저장\n",
        "for symbol in symbol_list :\n",
        "    df_rsi = get_rsi_performance_dataframe(symbol, start_date_, end_date_, fee_)\n",
        "    df_macd = get_macd_performance_dataframe(symbol, start_date_, end_date_, fee_)\n",
        "    df_sto = get_stochastic_performance_dataframe(symbol, start_date_, end_date_, fee_)\n",
        "\n",
        "    # write csv\n",
        "    df_rsi.to_csv(f'./rsi/{symbol}_{start_date_}_to_{end_date_}.csv',encoding='utf8', index=False)\n",
        "    df_macd.to_csv(f'./macd/{symbol}_{start_date_}_to_{end_date_}.csv',encoding='utf8', index=False)\n",
        "    df_sto.to_csv(f'./stochastic/{symbol}_{start_date_}_to_{end_date_}.csv',encoding='utf8', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9z9RT8wjzBq"
      },
      "outputs": [],
      "source": [
        "# Read_csv\n",
        "# Max CAGR, Max Sharpe Ratio 값 구하기\n",
        "# 해당 값에 해당하는 performance 값 계산 후 image 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Pm9Brz1j6fc"
      },
      "outputs": [],
      "source": [
        "# Max Parameter 를 이용하여 chart Graph 도출\n",
        "def get_rsi_max_performance(symbol, start_date_, end_date_, fee_, text) :\n",
        "    df_rsi = pd.read_csv(f'./rsi/{symbol}_{start_date_}_to_{end_date_}.csv',encoding='utf8', index=False)\n",
        "\n",
        "    max_series = df_rsi[df_rsi[text] == df_rsi[text].max()].iloc[0]\n",
        "    max_w = max_series['w_param']\n",
        "    max_buy = max_series['buy_param']\n",
        "    max_sell = max_series['sell_param']\n",
        "\n",
        "    print(f\"### {symbol}'s Parameter of max({text})\")\n",
        "    print(f\"{max_series}\")\n",
        "\n",
        "    df = fs.get_price(symbol, start_date=start_date_, end_date=end_date_)\n",
        "    # df = pd.read_csv(f\"get_price_{symbol}_{start_date_}_to_{end_date_}.csv\", encoding=\"utf8\", index_col=0, parse_dates=True)\n",
        "\n",
        "    # rsi\n",
        "    fs.rsi(df, w=max_w)\n",
        "    fs.draw_chart(df, left='rsi', right= symbol)\n",
        "    # 파일로 저장\n",
        "    plt.savefig(f\"./rsi/{symbol}_{text}_price_chart.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    # 리소스 해제\n",
        "    plt.close()\n",
        "\n",
        "    fs.indicator_to_signal(df, factor='rsi', buy=max_buy, sell=max_sell)\n",
        "    # Calc position\n",
        "    fs.position(df)\n",
        "    fs.draw_chart(df, left='rsi', right='position_chart')\n",
        "    # 파일로 저장\n",
        "    plt.savefig(f\"./rsi/{symbol}_{text}_position_chart.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    # 리소스 해제\n",
        "    plt.close()\n",
        "\n",
        "    # Evalution\n",
        "    fs.evaluate(df, cost= fee_)\n",
        "    fs.draw_chart(df, left='acc_rtn_dp', right=symbol)\n",
        "    # 파일로 저장\n",
        "    plt.savefig(f\"./rsi/{symbol}_{text}_evaluation_chart.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    # 리소스 해제\n",
        "    plt.close()\n",
        "\n",
        "    # get Performance\n",
        "    fs.performance(df, rf_rate=0.02)\n",
        "\n",
        "    fs.draw_trade_results(df)\n",
        "    # 파일로 저장\n",
        "    plt.savefig(f\"./rsi/{symbol}_{text}_trade_result_chart.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    # 리소스 해제\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDHLQaFvgsKM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iof6obbmgsWn"
      },
      "outputs": [],
      "source": [
        "# Max Parameter 를 이용하여 chart Graph 도출\n",
        "def get_macd_max_performance(symbol, start_date_, end_date_, fee_, text) :\n",
        "    df_macd = pd.read_csv(f'./macd/{symbol}_{start_date_}_to_{end_date_}.csv',encoding='utf8', index=False)\n",
        "\n",
        "    max_series = df_macd[df_macd[text] == df_macd[text].max()].iloc[0]\n",
        "    max_buy = max_series['buy_param']\n",
        "    max_sell = max_series['sell_param']\n",
        "\n",
        "    print(f\"### {symbol}'s Parameter of max({text})\")\n",
        "    print(f\"{max_series}\")\n",
        "\n",
        "    df = fs.get_price(symbol, start_date=start_date_, end_date=end_date_)\n",
        "    # df = pd.read_csv(f\"get_price_{symbol}_{start_date_}_to_{end_date_}.csv\", encoding=\"utf8\", index_col=0, parse_dates=True)\n",
        "\n",
        "    # macd\n",
        "    fs.macd(df)\n",
        "    fs.draw_chart(df, right=['macd','macd_signal','macd_oscillator'])\n",
        "    # 파일로 저장\n",
        "    plt.savefig(f\"./macd/{symbol}_{text}_price_chart.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    # 리소스 해제\n",
        "    plt.close()\n",
        "\n",
        "    fs.indicator_to_signal(df, factor='macd_oscillator', buy=max_buy, sell=max_sell)\n",
        "\n",
        "    # Calc position\n",
        "    fs.position(df)\n",
        "    fs.draw_chart(df, right='position_chart', left='macd_oscillator')\n",
        "    # 파일로 저장\n",
        "    plt.savefig(f\"./macd/{symbol}_{text}_position_chart.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    # 리소스 해제\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    # Evalution\n",
        "    fs.evaluate(df, cost=fee_)\n",
        "    fs.performance(df, rf_rate=0.02)\n",
        "    fs.draw_trade_results(df)\n",
        "    # 파일로 저장\n",
        "    plt.savefig(f\"./macd/{symbol}_{text}_trade_result_chart.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    # 리소스 해제\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaO_sGN-gscf"
      },
      "outputs": [],
      "source": [
        "# Max Parameter 를 이용하여 chart Graph 도출\n",
        "def get_stochastic_max_performance(symbol, start_date_, end_date_, fee_, text) :\n",
        "    df_sto = pd.read_csv(f'./stochastic/{symbol}_{start_date_}_to_{end_date_}.csv',encoding='utf8', index=False)\n",
        "\n",
        "    max_series = df_sto[df_sto[text] == df_sto[text].max()].iloc[0]\n",
        "    max_factor = max_series['factor']\n",
        "    max_buy = max_series['buy_param']\n",
        "    max_sell = max_series['sell_param']\n",
        "\n",
        "    print(f\"### {symbol}'s Parameter of max({text})\")\n",
        "    print(f\"{max_series}\")\n",
        "\n",
        "    df = fs.get_ohlc(symbol, start_date=start_date_, end_date=end_date_)\n",
        "    # df = pd.read_csv(f\"get_ohlc_{symbol}_{start_date_}_to_{end_date_}.csv\", encoding=\"utf8\", index_col=0, parse_dates=True)\n",
        "\n",
        "    # stochastic\n",
        "    fs.stochastic(df, symbol, n=14, m=3, t=3)\n",
        "    df['indicator'] = df['slow_k'] - df['slow_d']\n",
        "    fs.draw_chart(df, left=max_factor, right=symbol)\n",
        "    # 파일로 저장\n",
        "    plt.savefig(f\"./stochastic/{symbol}_{text}_price_chart.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    # 리소스 해제\n",
        "    plt.close()\n",
        "\n",
        "    fs.indicator_to_signal(df, factor=max_factor, buy=max_buy, sell=max_sell)\n",
        "\n",
        "    # Calc position\n",
        "    fs.position(df)\n",
        "    fs.draw_chart(df, right='position_chart', left='slow_k')\n",
        "    # # 파일로 저장\n",
        "    plt.savefig(f\"./stochastic/{symbol}_{text}_position_chart.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    # # 리소스 해제\n",
        "    # plt.close()\n",
        "\n",
        "\n",
        "    # Evalution\n",
        "    fs.evaluate(df, cost=fee_)\n",
        "    fs.performance(df, rf_rate=0.02)\n",
        "    fs.draw_trade_results(df)\n",
        "    # 파일로 저장\n",
        "    plt.savefig(f\"./stochastic/{symbol}_{text}_trade_result_chart.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    # 리소스 해제\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH400DG5ib-w"
      },
      "outputs": [],
      "source": [
        "cols = ['CAGR','Sharpe ratio']\n",
        "\n",
        "for symbol in symbol_list :\n",
        "    for col in cols :\n",
        "        get_rsi_max_performance(symbol, start_date_, end_date_, fee_, col)\n",
        "        get_macd_max_performance(symbol, start_date_, end_date_, fee_, col)\n",
        "        get_stochastic_max_performance(symbol, start_date_, end_date_, fee_, col)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
